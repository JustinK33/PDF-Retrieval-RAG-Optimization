{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "729aa8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in ./venv/lib/python3.12/site-packages (0.14.9)\n",
      "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in ./venv/lib/python3.12/site-packages (from llama-index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.9 in ./venv/lib/python3.12/site-packages (from llama-index) (0.14.9)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in ./venv/lib/python3.12/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in ./venv/lib/python3.12/site-packages (from llama-index) (0.9.4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in ./venv/lib/python3.12/site-packages (from llama-index) (0.6.10)\n",
      "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in ./venv/lib/python3.12/site-packages (from llama-index) (0.5.5)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in ./venv/lib/python3.12/site-packages (from llama-index) (0.5.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./venv/lib/python3.12/site-packages (from llama-index) (3.9.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (2025.10.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (2.11.5)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (3.6)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (2.3.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (10.4.0)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (2.12.5)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.9->llama-index) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.9->llama-index) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.9->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.9->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.9->llama-index) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.9->llama-index) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.9->llama-index) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.9->llama-index) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.9->llama-index) (1.22.0)\n",
      "Requirement already satisfied: griffe in ./venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (3.1.6)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./venv/lib/python3.12/site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.8.1)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.14.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: pandas<2.3.0 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.3)\n",
      "Requirement already satisfied: pypdf<7,>=6.1.3 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.4.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in ./venv/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./venv/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.9->llama-index) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in ./venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.11)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.9->llama-index) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.9->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.9->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (0.4.2)\n",
      "Requirement already satisfied: llama-cloud==0.1.35 in ./venv/lib/python3.12/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.54 in ./venv/lib/python3.12/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in ./venv/lib/python3.12/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.3.1)\n",
      "Requirement already satisfied: python-dotenv<2,>=1.0.1 in ./venv/lib/python3.12/site-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2025.11.3)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in ./venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.9->llama-index) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.9->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15.0,>=0.14.9->llama-index) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in ./venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.9->llama-index) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-index-llms-gemini in ./venv/lib/python3.12/site-packages (0.6.1)\n",
      "Requirement already satisfied: google-generativeai>=0.5.2 in ./venv/lib/python3.12/site-packages (from llama-index-llms-gemini) (0.8.5)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in ./venv/lib/python3.12/site-packages (from llama-index-llms-gemini) (0.14.9)\n",
      "Requirement already satisfied: pillow<11,>=10.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-llms-gemini) (10.4.0)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2025.10.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.11.5)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.6)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.3.5)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.12.5)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.22.0)\n",
      "Requirement already satisfied: griffe in ./venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./venv/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.4.2)\n",
      "Requirement already satisfied: idna>=2.0 in ./venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.11)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in ./venv/lib/python3.12/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in ./venv/lib/python3.12/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in ./venv/lib/python3.12/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./venv/lib/python3.12/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (2.43.0)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.12/site-packages (from google-generativeai>=0.5.2->llama-index-llms-gemini) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./venv/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./venv/lib/python3.12/site-packages (from google-api-core->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.72.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in ./venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in ./venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.5.2->llama-index-llms-gemini) (1.71.2)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in ./venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2025.11.12)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.6.1)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (8.3.1)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2025.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.4.2)\n",
      "Requirement already satisfied: greenlet>=1 in ./venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (25.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in ./venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in ./venv/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.5.2->llama-index-llms-gemini) (3.2.5)\n",
      "Requirement already satisfied: colorama>=0.4 in ./venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.4.6)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-llms-gemini) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pymupdf in ./venv/lib/python3.12/site-packages (1.26.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "ERROR: unknown command \"installllama-index-embeddings-huggingface\"\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nest_asyncio in ./venv/lib/python3.12/site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in ./venv/lib/python3.12/site-packages (from matplotlib) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
      "Collecting huggingface-hub>=0.19.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading huggingface_hub-1.1.7-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.13.0 in ./venv/lib/python3.12/site-packages (from llama-index-embeddings-huggingface) (0.14.9)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2025.10.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.11.5)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.6)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.3.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.12.5)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.22.0)\n",
      "Requirement already satisfied: griffe in ./venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./venv/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.2)\n",
      "Requirement already satisfied: idna>=2.0 in ./venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.11)\n",
      "Collecting filelock (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
      "Collecting shellingham (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typer-slim (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (4.12.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.16.0)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.7 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: click in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (8.3.1)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2025.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (2.5.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.57.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.56.1-py3-none-any.whl.metadata (42 kB)\n",
      "  Downloading transformers-4.56.0-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.55.3-py3-none-any.whl.metadata (41 kB)\n",
      "INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.55.1-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.55.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading transformers-4.54.0-py3-none-any.whl.metadata (41 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading transformers-4.53.3-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.52.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading transformers-4.52.1-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.44.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.43.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.42.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-4.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.38.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "  Downloading transformers-4.40.1-py3-none-any.whl.metadata (137 kB)\n",
      "  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "  Downloading transformers-4.39.2-py3-none-any.whl.metadata (134 kB)\n",
      "  Downloading transformers-4.39.1-py3-none-any.whl.metadata (134 kB)\n",
      "  Downloading transformers-4.39.0-py3-none-any.whl.metadata (134 kB)\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "  Downloading transformers-4.38.1-py3-none-any.whl.metadata (131 kB)\n",
      "  Downloading transformers-4.38.0-py3-none-any.whl.metadata (131 kB)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting numpy (from llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.34.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "  Downloading transformers-4.37.1-py3-none-any.whl.metadata (129 kB)\n",
      "  Downloading transformers-4.37.0-py3-none-any.whl.metadata (129 kB)\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "  Downloading transformers-4.36.1-py3-none-any.whl.metadata (126 kB)\n",
      "  Downloading transformers-4.36.0-py3-none-any.whl.metadata (126 kB)\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "  Downloading transformers-4.35.1-py3-none-any.whl.metadata (123 kB)\n",
      "  Downloading transformers-4.35.0-py3-none-any.whl.metadata (123 kB)\n",
      "  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers<5.0.0,>=4.32.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.33.3-py3-none-any.whl.metadata (119 kB)\n",
      "  Downloading transformers-4.33.2-py3-none-any.whl.metadata (119 kB)\n",
      "  Downloading transformers-4.33.1-py3-none-any.whl.metadata (119 kB)\n",
      "  Downloading transformers-4.33.0-py3-none-any.whl.metadata (119 kB)\n",
      "  Downloading transformers-4.32.1-py3-none-any.whl.metadata (118 kB)\n",
      "  Downloading transformers-4.32.0-py3-none-any.whl.metadata (118 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.7 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting huggingface-hub[inference]>=0.19.0 (from llama-index-embeddings-huggingface)\n",
      "  Downloading huggingface_hub-1.1.6-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.6 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.1.6 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading huggingface_hub-1.1.5-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.5 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.1.5 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading huggingface_hub-1.1.4-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.4 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.1.4 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading huggingface_hub-1.1.3-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.3 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.1.3 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.2 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.1.2 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading huggingface_hub-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.1 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.1.1 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading huggingface_hub-1.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.1.0 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.1.0 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "\u001b[33mWARNING: huggingface-hub 1.0.1 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: huggingface-hub 1.0.1 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading huggingface_hub-1.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: greenlet>=1 in ./venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.2.4)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.26.1)\n",
      "Requirement already satisfied: colorama>=0.4 in ./venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.0->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\n",
      "Downloading torch-2.9.1-cp312-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.3-cp312-cp312-macosx_14_0_arm64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, hf-xet, filelock, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers, llama-index-embeddings-huggingface\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m14/14\u001b[0m [llama-index-embeddings-huggingface]ansformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.20.0 hf-xet-1.2.0 huggingface-hub-0.36.0 llama-index-embeddings-huggingface-0.6.1 mpmath-1.3.0 safetensors-0.7.0 scikit-learn-1.7.2 scipy-1.16.3 sentence-transformers-5.1.2 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index \n",
    "%pip install llama-index-llms-gemini\n",
    "%pip install pymupdf\n",
    "%pip install nest_asyncio\n",
    "%pip install matplotlib\n",
    "%pip install python-dotenv\n",
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84022c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89df3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n",
    "if GOOGLE_API_KEY is None:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found. Did you create a .env file?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78333332",
   "metadata": {},
   "source": [
    "first load and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dc610f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def upload_pdf(pdf_path: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Select a local PDF file and copy it into the sample_docs directory.\n",
    "    Returns the path to the copied PDF.\n",
    "    \"\"\"\n",
    "    if pdf_path is None:\n",
    "        pdf_path = input(\"Enter the full or relative path to your PDF file: \").strip()\n",
    "\n",
    "    src = Path(pdf_path)\n",
    "\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {src}\")\n",
    "    if src.suffix.lower() != \".pdf\":\n",
    "        raise ValueError(f\"File is not a PDF: {src}\")\n",
    "\n",
    "    dest_dir = Path(\"sample_docs\")\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dest = dest_dir / src.name\n",
    "    shutil.copy(src, dest)\n",
    "\n",
    "    print(f\"PDF copied to {dest}\")\n",
    "    return str(dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c07c306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF copied to sample_docs/LenderFeesWorksheetNew.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_path = upload_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e855a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"Extract text from a PDF file using PyMuPDF.\"\"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        text = \"\\n\".join(page.get_text() for page in doc)\n",
    "\n",
    "        print(f\"PDF: {pdf_path}\")\n",
    "        print(f\"Number of pages: {len(doc)}\")\n",
    "        print(f\"Extracted {len(text.split())} words from the PDF.\")\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4d8b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF: sample_docs/LenderFeesWorksheetNew.pdf\n",
      "Number of pages: 1\n",
      "Extracted 404 words from the PDF.\n",
      "Your actual rate, payment, and cost could be higher. Get an official Loan Estimate before choosing a loan.\n",
      "Fee Details and Summary\n",
      "Applicants:\n",
      "Application No:\n",
      "Date Prepared:\n",
      "Loan Program:\n",
      "Prepared By:\n",
      "THIS IS NOT A GOOD FAITH ESTIMATE (GFE). This \"Fees Worksheet\" is provided for informational purposes ONLY, to assist\n",
      "you in determining an estimate of cash that may be required to close and an estimate of your proposed monthly mortgage \n",
      "payment. Actual charges may be more or less, and your transac\n"
     ]
    }
   ],
   "source": [
    "if pdf_path:\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f642184",
   "metadata": {},
   "source": [
    "set up a custom loader to integrate PyMuPDF with LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d4dce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core import Document\n",
    "\n",
    "def load_pdf_with_pymupdf(pdf_path: str) -> List[Document]:\n",
    "    documents: List[Document] = []\n",
    "\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        total_pages = len(doc)\n",
    "\n",
    "        for i, page in enumerate(doc):\n",
    "            text = page.get_text()\n",
    "\n",
    "            if not text.strip():\n",
    "                continue\n",
    "\n",
    "            documents.append(\n",
    "                Document(\n",
    "                    text=text,\n",
    "                    metadata={\n",
    "                        \"file_name\": os.path.basename(pdf_path),\n",
    "                        \"page_number\": i + 1,\n",
    "                        \"total_pages\": total_pages\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(f\"Processed {pdf_path}:\")\n",
    "    print(f\"Extracted {len(documents)} pages with content\")\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e00fd618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sample_docs/LenderFeesWorksheetNew.pdf:\n",
      "Extracted 1 pages with content\n"
     ]
    }
   ],
   "source": [
    "pdf_docs = load_pdf_with_pymupdf(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690762c3",
   "metadata": {},
   "source": [
    "create the indexing infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3032b8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-1.5-flash\")\n",
    "Settings.llm = llm\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "def process_and_index_pdf(pdf_path: str) -> VectorStoreIndex:\n",
    "    documents = load_pdf_with_pymupdf(pdf_path)\n",
    "    vector_index = VectorStoreIndex.from_documents(documents)\n",
    "    print(f\"Indexed {len(documents)} document chunks\")\n",
    "    return vector_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = process_and_index_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc393d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-1.5-flash\")\n",
    "Settings.llm = llm\n",
    "\n",
    "def expand_query(query: str, num_expansions: int = 3) -> list:\n",
    "    prompt = f\"\"\"\n",
    "    I need to search a legal contract with this query: \"{query}\"\n",
    "\n",
    "    Please help me expand this query by generating {num_expansions} alternative versions that:\n",
    "    1. Use different but related terminology\n",
    "    2. Include relevant legal terms that might appear in a contract\n",
    "    3. Cover similar concepts but phrased differently\n",
    "\n",
    "    Format your response as a list of alternative queries only, with no additional text.\n",
    "    \"\"\"\n",
    "    response = llm.complete(prompt)\n",
    "    expanded_queries = [line.strip() for line in response.text.split(\"\\n\") if line.strip()]\n",
    "    if query not in expanded_queries:\n",
    "        expanded_queries = [query] + expanded_queries\n",
    "    return expanded_queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = expand_query(\"What are the penalties for late payments?\")\n",
    "for i, q in enumerate(expanded):\n",
    "    print(f\"{i+1}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef09c1",
   "metadata": {},
   "source": [
    "structured query expansion using LlamaIndex's built-in functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2eb1945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "\n",
    "def create_query_expansion_engine(index):\n",
    "    base_retriever = index.as_retriever(similarity_top_k=2)\n",
    "\n",
    "    fusion_retriever = QueryFusionRetriever(\n",
    "        retrievers=[base_retriever],\n",
    "        llm=llm,\n",
    "        similarity_top_k=2,\n",
    "        num_queries=3,\n",
    "        mode=\"reciprocal_rerank\"\n",
    "    )\n",
    "\n",
    "    query_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever=fusion_retriever,\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    return query_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4687c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_query_engine = create_query_expansion_engine(index)\n",
    "response = expanded_query_engine.query(\"What are the penalties for late payments?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee6b92",
   "metadata": {},
   "source": [
    "hybrid retrieval combines embedding-based semantic search with keyword-based retrieval for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07feb016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-retrievers-bm25\n",
      "  Downloading llama_index_retrievers_bm25-0.6.5-py3-none-any.whl.metadata (446 bytes)\n",
      "Collecting bm25s>=0.2.7.post1 (from llama-index-retrievers-bm25)\n",
      "  Downloading bm25s-0.2.14-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: llama-index-core<0.15,>=0.13.1 in ./venv/lib/python3.12/site-packages (from llama-index-retrievers-bm25) (0.14.9)\n",
      "Collecting pystemmer<3,>=2.2.0.1 (from llama-index-retrievers-bm25)\n",
      "  Downloading PyStemmer-2.2.0.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.13.2)\n",
      "Requirement already satisfied: aiosqlite in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.2.0)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2025.10.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.11.5)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.6)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.9.2)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.3.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (10.4.0)\n",
      "Requirement already satisfied: platformdirs in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (4.5.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.12.5)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in ./venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.0.44)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.12/site-packages (from llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.17.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.22.0)\n",
      "Requirement already satisfied: griffe in ./venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.15.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.1.6)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in ./venv/lib/python3.12/site-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.4.2)\n",
      "Requirement already satisfied: idna>=2.0 in ./venv/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.11)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.12/site-packages (from bm25s>=0.2.7.post1->llama-index-retrievers-bm25) (1.16.3)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (8.3.1)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2025.11.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (2025.11.12)\n",
      "Requirement already satisfied: greenlet>=1 in ./venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in ./venv/lib/python3.12/site-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.4.6)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (4.12.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15,>=0.13.1->llama-index-retrievers-bm25) (3.0.3)\n",
      "Downloading llama_index_retrievers_bm25-0.6.5-py3-none-any.whl (5.0 kB)\n",
      "Downloading PyStemmer-2.2.0.3-cp312-cp312-macosx_11_0_arm64.whl (220 kB)\n",
      "Downloading bm25s-0.2.14-py3-none-any.whl (55 kB)\n",
      "Installing collected packages: pystemmer, bm25s, llama-index-retrievers-bm25\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3/3\u001b[0m [llama-index-retrievers-bm25]\n",
      "\u001b[1A\u001b[2KSuccessfully installed bm25s-0.2.14 llama-index-retrievers-bm25-0.6.5 pystemmer-2.2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-retrievers-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "def create_hybrid_retriever(index, query, top_k: int = 2):\n",
    "    vector_retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    vector_nodes = vector_retriever.retrieve(query)\n",
    "\n",
    "    nodes = list(index.docstore.docs.values())\n",
    "    bm25_retriever = BM25Retriever.from_defaults(\n",
    "        nodes=nodes,\n",
    "        similarity_top_k=top_k\n",
    "    )\n",
    "    keyword_nodes = bm25_retriever.retrieve(query)\n",
    "\n",
    "    all_nodes = list(vector_nodes) + list(keyword_nodes)\n",
    "\n",
    "    unique_nodes = []\n",
    "    seen_ids = set()\n",
    "    for node in all_nodes:\n",
    "        if node.node_id not in seen_ids:\n",
    "            unique_nodes.append(node)\n",
    "            seen_ids.add(node.node_id)\n",
    "\n",
    "    sorted_nodes = sorted(\n",
    "        unique_nodes,\n",
    "        key=lambda x: x.score if hasattr(x, \"score\") else 0.0,\n",
    "        reverse=True,\n",
    "    )\n",
    "\n",
    "    return sorted_nodes[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fd4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_nodes = create_hybrid_retriever(index, \"What is the refund policy?\")\n",
    "for i, node in enumerate(hybrid_nodes):\n",
    "    print(f\"Result {i+1} (Score: {node.score:.4f}):\")\n",
    "    print(node.get_text())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43016a0",
   "metadata": {},
   "source": [
    "create a function to compare different retrieval methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9760463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_retrieval_methods(index, query: str, top_k: int = 2):\n",
    "    vector_retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    vector_nodes = vector_retriever.retrieve(query)\n",
    "\n",
    "    nodes = list(index.docstore.docs.values())\n",
    "    keyword_retriever = BM25Retriever.from_defaults(\n",
    "        nodes=nodes,\n",
    "        similarity_top_k=top_k\n",
    "    )\n",
    "    keyword_nodes = keyword_retriever.retrieve(query)\n",
    "\n",
    "    hybrid_nodes = create_hybrid_retriever(index, query, top_k)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for method, nodes_list in [\n",
    "        (\"Vector (Semantic)\", vector_nodes),\n",
    "        (\"Keyword (BM25)\", keyword_nodes),\n",
    "        (\"Hybrid\", hybrid_nodes),\n",
    "    ]:\n",
    "        for i, node in enumerate(nodes_list):\n",
    "            results.append(\n",
    "                {\n",
    "                    \"Method\": method,\n",
    "                    \"Rank\": i + 1,\n",
    "                    \"Score\": node.score if hasattr(node, \"score\") else 0.0,\n",
    "                    \"Content\": node.get_text()[:200] + \"...\",\n",
    "                    \"Page\": node.metadata.get(\"page_number\", \"Unknown\")\n",
    "                    if hasattr(node, \"metadata\")\n",
    "                    else \"Unknown\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    display(results_df)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for method in [\"Vector (Semantic)\", \"Keyword (BM25)\", \"Hybrid\"]:\n",
    "        method_df = results_df[results_df[\"Method\"] == method]\n",
    "        plt.bar(\n",
    "            [f\"{method} - Rank {row['Rank']}\" for _, row in method_df.iterrows()],\n",
    "            method_df[\"Score\"],\n",
    "            alpha=0.7,\n",
    "            label=method,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Result\")\n",
    "    plt.ylabel(\"Retrieval Score\")\n",
    "    plt.title(f\"Comparison of Retrieval Methods for Query: '{query}'\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82375ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = compare_retrieval_methods(index, \"What is the refund policy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bdbef0",
   "metadata": {},
   "source": [
    "reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "469da135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "def rerank_results(nodes, query: str, top_n: int = 2):\n",
    "    reranker = SentenceTransformerRerank(\n",
    "        model=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "        top_n=top_n\n",
    "    )\n",
    "    reranked_nodes = reranker.postprocess_nodes(\n",
    "        nodes,\n",
    "        query_str=query\n",
    "    )\n",
    "    return reranked_nodes\n",
    "\n",
    "def demonstrate_reranking(index, query: str, top_k: int = 4):\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    nodes = retriever.retrieve(query)\n",
    "\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"\\nOriginal Retrieval Order:\")\n",
    "    for i, node in enumerate(nodes):\n",
    "        print(f\"{i+1}. (Score: {node.score:.4f}) - {node.get_text()[:100]}...\")\n",
    "\n",
    "    reranked_nodes = rerank_results(nodes, query, top_n=2)\n",
    "\n",
    "    print(\"\\nAfter Reranking:\")\n",
    "    for i, node in enumerate(reranked_nodes):\n",
    "        print(f\"{i+1}. (Score: {node.score:.4f}) - {node.get_text()[:100]}...\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i, node in enumerate(nodes):\n",
    "        results.append({\n",
    "            \"Stage\": \"Original Retrieval\",\n",
    "            \"Rank\": i + 1,\n",
    "            \"Score\": node.score,\n",
    "            \"Content\": node.get_text()[:150] + \"...\",\n",
    "            \"Page\": node.metadata.get(\"page_number\", \"Unknown\"),\n",
    "        })\n",
    "\n",
    "    for i, node in enumerate(reranked_nodes):\n",
    "        results.append({\n",
    "            \"Stage\": \"After Reranking\",\n",
    "            \"Rank\": i + 1,\n",
    "            \"Score\": node.score,\n",
    "            \"Content\": node.get_text()[:150] + \"...\",\n",
    "            \"Page\": node.metadata.get(\"page_number\", \"Unknown\"),\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    display(results_df)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5675cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranking_demo = demonstrate_reranking(index, \"What happens if I cancel the service?\", top_k=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5966e1",
   "metadata": {},
   "source": [
    "advanced RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00df2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "\n",
    "def build_rag_pipeline(index):\n",
    "    nodes = list(index.docstore.docs.values())\n",
    "    num_nodes = len(nodes)\n",
    "    safe_top_k = min(2, max(1, num_nodes))\n",
    "\n",
    "    print(f\"Index contains {num_nodes} nodes, using top_k={safe_top_k}\")\n",
    "\n",
    "    vector_retriever = index.as_retriever(\n",
    "        similarity_top_k=safe_top_k\n",
    "    )\n",
    "\n",
    "    bm25_retriever = BM25Retriever.from_defaults(\n",
    "        nodes=nodes,\n",
    "        similarity_top_k=safe_top_k\n",
    "    )\n",
    "\n",
    "    class HybridRetriever(BaseRetriever):\n",
    "        def __init__(self, vector_retriever, keyword_retriever, top_k: int = 2):\n",
    "            self.vector_retriever = vector_retriever\n",
    "            self.keyword_retriever = keyword_retriever\n",
    "            self.top_k = top_k\n",
    "            super().__init__()\n",
    "\n",
    "        def _retrieve(self, query_bundle, **kwargs):\n",
    "            vector_nodes = self.vector_retriever.retrieve(query_bundle)\n",
    "            keyword_nodes = self.keyword_retriever.retrieve(query_bundle)\n",
    "            all_nodes = list(vector_nodes) + list(keyword_nodes)\n",
    "\n",
    "            unique_nodes = {}\n",
    "            for node in all_nodes:\n",
    "                if node.node_id not in unique_nodes:\n",
    "                    unique_nodes[node.node_id] = node\n",
    "\n",
    "            sorted_nodes = sorted(\n",
    "                unique_nodes.values(),\n",
    "                key=lambda x: x.score if hasattr(x, \"score\") else 0.0,\n",
    "                reverse=True,\n",
    "            )\n",
    "\n",
    "            return sorted_nodes[:self.top_k]\n",
    "\n",
    "    hybrid_retriever = HybridRetriever(\n",
    "        vector_retriever=vector_retriever,\n",
    "        keyword_retriever=bm25_retriever,\n",
    "        top_k=safe_top_k,\n",
    "    )\n",
    "\n",
    "    node_postprocessors = []\n",
    "    if num_nodes > 1:\n",
    "        reranker = SentenceTransformerRerank(\n",
    "            model=\"cross-encoder/ms-marco-MiniLM-L-6-v2\",\n",
    "            top_n=min(2, num_nodes),\n",
    "        )\n",
    "        node_postprocessors = [reranker]\n",
    "\n",
    "    query_engine = RetrieverQueryEngine.from_args(\n",
    "        retriever=hybrid_retriever,\n",
    "        llm=llm,\n",
    "        node_postprocessors=node_postprocessors,\n",
    "    )\n",
    "\n",
    "    return query_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69269bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = process_and_index_pdf(pdf_path)\n",
    "rag_engine = build_rag_pipeline(index)\n",
    "response = rag_engine.query(\"What are the penalties for late payments?\")\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
